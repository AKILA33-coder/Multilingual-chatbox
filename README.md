# ğŸ­ ECHO â€“ The Multimodal Emotional Intelligence Engine

ECHO is an AI-powered multimodal emotion recognition system that analyzes **text and voice inputs** to understand human emotions more accurately.  
Unlike traditional sentiment analysis systems that rely only on text, ECHO combines **Natural Language Processing (NLP)** and **Audio Signal Processing** to detect emotions in a human-like manner.

---

## ğŸ“Œ Project Overview

- **Project Type:** AI / ML Mini Project  
- **Course:** CS2581 â€“ Artificial Intelligence and Machine Learning Laboratory  
- **Institution:** PSNA College of Engineering and Technology  
- **Developed By:** Akila S, Afila Nishath K, Devadharshini S, Deetchini V  

---

## ğŸ¯ Objectives

- Understand emotions from **multilingual text and voice inputs**
- Detect emotional context such as **Happy, Sad, and Neutral**
- Improve emotion recognition accuracy using **Transformer models**
- Generate **actionable outputs** like music, movie, and book suggestions
- Visualize emotions using **interactive graphs**

---

## ğŸš€ Key Features

- ğŸ§  Multimodal Emotion Detection (Text + Audio)
- ğŸŒ Multilingual Text Support
- ğŸµ Emotion-based Music & Content Suggestions
- ğŸ“Š 3D Mood Visualization Graph
- ğŸ’¬ Interactive Chat Interface
- ğŸ—‚ï¸ Chat History Storage using SQLite
- âš¡ Real-time Emotion Analysis

---

## ğŸ› ï¸ Technologies Used

### Programming & Frameworks
- Python
- Streamlit
- TensorFlow / PyTorch

### Libraries
- Transformers
- TextBlob
- Librosa
- Scikit-learn
- Matplotlib
- Plotly
- Seaborn

### Database
- SQLite3

---

## ğŸ§© System Architecture

1. User inputs text or audio  
2. Text is processed using NLP & Transformer models  
3. Audio is analyzed using acoustic features (pitch, tone, frequency)  
4. Emotion scores are combined using weighted fusion  
5. Emotion is classified and visualized  
6. Personalized suggestions are generated  

---

## ğŸ“‚ Dataset Description

- Multilingual text samples with emotion labels
- Voice recordings capturing pitch, tone, and intensity
- Preprocessing includes:
  - Noise removal
  - Feature extraction
  - Data normalization

---

## ğŸ“ˆ Results

- Accuracy above **90%**
- High Precision, Recall, and F1-score
- Better performance compared to text-only models
- Effective detection of subtle emotional transitions

---

## ğŸ–¥ï¸ Output Screens

- Multilingual chatbot interface
- Emotion-aware chat responses
- Mood-based recommendations
- Interactive 3D mood graph

---

## ğŸ“Œ Applications

- Emotion-aware chatbots
- Mental health support systems
- Virtual assistants
- Customer service analysis
- Human-computer interaction systems

---

## ğŸ”® Future Enhancements

- Facial emotion recognition
- Real-time speech emotion analysis
- More emotion categories
- Mobile & cloud deployment

---

## â¤ï¸ Acknowledgement

This project was developed as part of the **AI & ML Laboratory** under the guidance of faculty members at PSNA College of Engineering and Technology.

---

## ğŸ“œ License

This project is for **academic and educational purposes only**.
